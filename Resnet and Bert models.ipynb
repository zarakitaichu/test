{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "913THLmGd_AD"
      },
      "outputs": [],
      "source": [
        "# Check Python Version\n",
        "!python --version"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Ubuntu Version\n",
        "!lsb_release -a"
      ],
      "metadata": {
        "id": "VnxTPjb9eA5M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check CUDA/cuDNN Version\n",
        "!nvcc -V && which nvcc"
      ],
      "metadata": {
        "id": "qRbcv-rkeA7T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check GPU\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "kQWdT_IqeA9S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This get the RAPIDS-Colab install files and test check your GPU.  Run this and the next cell only.\n",
        "# Please read the output of this cell.  If your Colab Instance is not RAPIDS compatible, it will warn you and give you remediation steps.\n",
        "!git clone https://github.com/rapidsai/rapidsai-csp-utils.git\n",
        "!python rapidsai-csp-utils/colab/pip-install.py"
      ],
      "metadata": {
        "id": "FVUoOccxeA_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "J_KdFoPTeBDr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cudf\n",
        "import gc\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas()\n",
        "import random\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import  models, transforms\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from cuml.feature_extraction.text import TfidfVectorizer\n",
        "from cuml.neighbors import NearestNeighbors\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "import glob\n",
        "from PIL import Image\n",
        "import seaborn as sns\n",
        "import cv2, matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from textwrap import wrap"
      ],
      "metadata": {
        "id": "HsZtvnOseBFp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7tLS5XceBHe",
        "outputId": "15b9b2e4-7daa-4977-b978-01ae67ea3f0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "RMch1iUEeBJT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/MyDrive/Shopee/'"
      ],
      "metadata": {
        "id": "llnatzsZfcQu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv(path+'train.csv')\n",
        "# test_df = pd.read_csv(path+'test.csv')"
      ],
      "metadata": {
        "id": "ErzE4nFrfcTY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.shape"
      ],
      "metadata": {
        "id": "C8otyj7MfcVn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head()"
      ],
      "metadata": {
        "id": "UnibwuBBfcX1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda'if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "metadata": {
        "id": "gsStSgQtfcaE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tmp = train_df.groupby('label_group').posting_id.agg('unique').to_dict()\n",
        "train_df['target'] = train_df.label_group.map(tmp)"
      ],
      "metadata": {
        "id": "qx6bWv4PfccB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_random_img():\n",
        "    # choose randomly two instances per each class\n",
        "    labels_to_show = np.random.choice(train_df.label_group.unique(), \n",
        "                                      replace=False, size=24)\n",
        "    img_to_show = []\n",
        "    for label in labels_to_show:\n",
        "        rows = train_df[train_df.label_group==label].copy()\n",
        "        pair = np.random.choice([i for i in range(len(rows))], \n",
        "                                    replace=False, size=2)\n",
        "        img_pair = rows.iloc[pair][['image', 'title']].values\n",
        "        \n",
        "        img_to_show += list(img_pair)\n",
        "    \n",
        "    fig, axes = plt.subplots(figsize = (18, 12), nrows=4,ncols=6)\n",
        "    for imp, ax in zip(img_to_show, axes.ravel()):\n",
        "        img = cv2.imread(path+'train_images/' + imp[0])\n",
        "        title = '\\n'.join(wrap(imp[1], 20))\n",
        "        ax.set_title(title)\n",
        "        ax.imshow(img)\n",
        "        ax.axis('off')\n",
        "\n",
        "    fig.tight_layout()"
      ],
      "metadata": {
        "id": "BZ5raaqPfceS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_random_img()"
      ],
      "metadata": {
        "id": "7WdZicQZfcgY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNetEmbedder(nn.Module):\n",
        "    \n",
        "    def __init__(self, device='cpu'):\n",
        "        super(ResNetEmbedder, self).__init__()\n",
        "        self.model = models.resnet50(pretrained=False)\n",
        "        self.device = device\n",
        "        path = '/content/drive/MyDrive/Shopee/resnet50-19c8e357.pth'\n",
        "        self.model.load_state_dict(torch.load(path))\n",
        "#         to freeze weights\n",
        "        for param in self.model.parameters():\n",
        "                param.requires_grad = False\n",
        "        self.model.to(device)\n",
        "        \n",
        "    \n",
        "    def transform(self, img):\n",
        "        image_transform = torchvision.transforms.Compose(\n",
        "            [\n",
        "                torchvision.transforms.Resize(256),\n",
        "                transforms.CenterCrop(224),\n",
        "                torchvision.transforms.ToTensor(),\n",
        "                torchvision.transforms.Normalize(\n",
        "                    mean=(0.485, 0.456, 0.406), \n",
        "                    std=(0.229, 0.224, 0.225)\n",
        "                ),\n",
        "            ]\n",
        "        )\n",
        "        return image_transform(img)\n",
        "    \n",
        "    def forward(self, img):\n",
        "        img_tr = self.transform(img).unsqueeze(0)\n",
        "        img_tr = img_tr.to(self.device)\n",
        "        features = self.model(img_tr).squeeze()\n",
        "        return features"
      ],
      "metadata": {
        "id": "PZ8d-PDuf8e5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_img = ResNetEmbedder(device)"
      ],
      "metadata": {
        "id": "4hvDdYualEZp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def vectorize_img(img_path):\n",
        "    img = Image.open(img_path).convert('RGB')\n",
        "    model_img.eval()\n",
        "    with torch.no_grad():\n",
        "        output = model_img(img).cpu().numpy()\n",
        "    return output"
      ],
      "metadata": {
        "id": "EbH6FJo4lHtV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "train_df['resnet_v'] = train_df['image'].progress_apply(lambda x: vectorize_img(path+'train_images/' + x))"
      ],
      "metadata": {
        "id": "-KZjHTr9mqYB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_df.to_csv('/content/drive/MyDrive/Shopee/train_df_bkp.csv')\n",
        "# train_df.to_pickle('/content/drive/MyDrive/Shopee/train_df_pkl')"
      ],
      "metadata": {
        "id": "4TwHdd3poSxq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del model_img"
      ],
      "metadata": {
        "id": "ge2DXpVWnCGG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# normalize vectors\n",
        "vectors = np.stack(train_df.resnet_v)\n",
        "vectors = torch.Tensor(vectors).to(device)\n",
        "vectors = F.normalize(vectors)"
      ],
      "metadata": {
        "id": "fCx8iY_vni-X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# find the closest vectors for each image using cosine similarity via a threshold, based on ResNet embeddings\n",
        "\n",
        "preds = []\n",
        "CHUNK = 1024\n",
        "\n",
        "CTS = len(train_df) // CHUNK\n",
        "\n",
        "if len(train_df) % CHUNK != 0:\n",
        "  CTS += 1\n",
        "\n",
        "for j in range(CTS):\n",
        "    \n",
        "    a = j * CHUNK\n",
        "    b = (j + 1) * CHUNK\n",
        "    b = min(b, len(train_df))\n",
        "    print('chunk', a, 'to', b)\n",
        "    \n",
        "    # COSINE SIMILARITY DISTANCE\n",
        "    cts = torch.matmul( vectors, vectors[a:b].T).T\n",
        "    cts = cts.cpu().numpy()\n",
        "    \n",
        "    for k in range(b-a):\n",
        "        IDX = np.where(cts[k,] > 0.9)[0]\n",
        "        o = train_df.iloc[IDX].posting_id.values\n",
        "        preds.append(o)\n",
        "\n",
        "del vectors, cts, IDX, o\n",
        "_ = gc.collect()"
      ],
      "metadata": {
        "id": "vmR51iBznjA2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['preds_resnet'] = preds\n",
        "train_df.head()"
      ],
      "metadata": {
        "id": "hB6dlVf8njDN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getMetric(col):\n",
        "    def f1score(row):\n",
        "        n = len( np.intersect1d(row.target,row[col]) )\n",
        "        return 2*n / (len(row.target)+len(row[col]))\n",
        "    return f1score"
      ],
      "metadata": {
        "id": "0dAYOP7jnjFm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['f1_resnet'] = train_df.apply(getMetric('preds_resnet'), axis=1)\n",
        "print('CV score via image embeddings =', train_df.f1_resnet.mean())"
      ],
      "metadata": {
        "id": "G9PHIlUXnjH9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BERTEmbedder(nn.Module):\n",
        "    \n",
        "    def __init__(self, device='cpu'):\n",
        "        super(BERTEmbedder, self).__init__()\n",
        "        self.bert_path = \"../input/sentence-transformer/\"\n",
        "        self.model = BertModel.from_pretrained(self.bert_path)\n",
        "#         to freeze weights\n",
        "        for param in self.model.parameters():\n",
        "                param.requires_grad = False\n",
        "        self.model.to(device)\n",
        "        \n",
        "    def transform(self, txt):\n",
        "        tokenizer = BertTokenizer.from_pretrained(self.bert_path)\n",
        "        encoded_input  = tokenizer.encode_plus( txt, \n",
        "                                                truncation=True, \n",
        "                                                max_length=128,\n",
        "                                                add_special_tokens=True,\n",
        "                                                padding=True,\n",
        "                                                return_tensors='pt').values()\n",
        "        return encoded_input\n",
        "    \n",
        "    def mean_pooling(self, model_output, attention_mask):\n",
        "        token_embeddings = model_output[0]\n",
        "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
        "        sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
        "        sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
        "        return sum_embeddings / sum_mask\n",
        "        \n",
        "    def forward(self, txt):\n",
        "        inputs_ids, token_type_ids, attention_mask = self.transform(txt)\n",
        "        inputs_ids, token_type_ids, attention_mask = inputs_ids.to(device), \\\n",
        "                                                token_type_ids.to(device), attention_mask.to(device)\n",
        "        with torch.no_grad():\n",
        "            encoded_layers = self.model(inputs_ids, \n",
        "                                        attention_mask=attention_mask, \n",
        "                                        token_type_ids=token_type_ids)\n",
        "        features = self.mean_pooling(encoded_layers, attention_mask)\n",
        "        return features"
      ],
      "metadata": {
        "id": "N9wsnfghnjKL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_txt = BERTEmbedder(device)"
      ],
      "metadata": {
        "id": "aPWx5H9anjMW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def vectorize_txt(txt):\n",
        "    model_txt.eval()\n",
        "    with torch.no_grad():\n",
        "        output = model_txt(txt).cpu().numpy()\n",
        "    return output"
      ],
      "metadata": {
        "id": "vRe4CR1lnjOn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "train_df['sbert_v'] = train_df['title'].progress_apply(lambda x: vectorize_txt(x))"
      ],
      "metadata": {
        "id": "XmAT-J2JnjRC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del model_txt"
      ],
      "metadata": {
        "id": "aM3UtUgInjTY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectors = np.stack(train_df.sbert_v).squeeze(1)\n",
        "vectors = torch.Tensor(vectors).to(device)\n",
        "vectors = F.normalize(vectors)"
      ],
      "metadata": {
        "id": "YUlLUCt0njV-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = []\n",
        "CHUNK = 1024\n",
        "\n",
        "print('Finding similar titles...')\n",
        "CTS = len(train_df)//CHUNK\n",
        "if len(train_df)%CHUNK!=0: CTS += 1\n",
        "for j in range( CTS ):\n",
        "    \n",
        "    a = j*CHUNK\n",
        "    b = (j+1)*CHUNK\n",
        "    b = min(b,len(train_df))\n",
        "    print('chunk',a,'to',b)\n",
        "    \n",
        "    # COSINE SIMILARITY DISTANCE\n",
        "    cts = torch.matmul( vectors, vectors[a:b].T).T\n",
        "    cts = cts.cpu().numpy()\n",
        "    \n",
        "    for k in range(b-a):\n",
        "        IDX = np.where(cts[k,]>0.95)[0]\n",
        "        o = train_df.iloc[IDX].posting_id.values\n",
        "        preds.append(o)\n",
        "\n",
        "del vectors, cts, IDX, o\n",
        "_ = gc.collect()"
      ],
      "metadata": {
        "id": "zVfU7dYVnjYU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['preds_sbert'] = preds\n",
        "train_df.head()"
      ],
      "metadata": {
        "id": "eyXC4LiKnjae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del preds"
      ],
      "metadata": {
        "id": "VXqMSN3gnjeC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['f1_sbert'] = train_df.apply(getMetric('preds_sbert'), axis=1)\n",
        "print('CV score via title embeddings =', train_df.f1_sbert.mean())"
      ],
      "metadata": {
        "id": "e3y_HmRv8F3E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def concat():\n",
        "    def cat(row):\n",
        "        comm = np.concatenate([row.resnet_v,row.sbert_v.squeeze()])\n",
        "        return comm\n",
        "    return cat"
      ],
      "metadata": {
        "id": "8goEFljH8F7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['concat_v'] = train_df.progress_apply(concat(), axis=1)"
      ],
      "metadata": {
        "id": "whhnt20c8F-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectors = np.stack(train_df.concat_v)"
      ],
      "metadata": {
        "id": "wz9v4xF48GCL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "KNN = 50\n",
        "model = NearestNeighbors(n_neighbors=KNN)\n",
        "model.fit(vectors)"
      ],
      "metadata": {
        "id": "6U9NUf1Q8R5A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = []\n",
        "CHUNK = 1024*4\n",
        "\n",
        "print('Finding similar images...')\n",
        "CTS = len(vectors)//CHUNK\n",
        "if len(vectors)%CHUNK!=0: CTS += 1\n",
        "for j in range( CTS ):\n",
        "    \n",
        "    a = j*CHUNK\n",
        "    b = (j+1)*CHUNK\n",
        "    b = min(b,len(vectors))\n",
        "    print('chunk',a,'to',b)\n",
        "    distances, indices = model.kneighbors(vectors[a:b,])\n",
        "    \n",
        "    for k in range(b-a):\n",
        "        IDX = np.where(distances[k,]<35.0)[0]\n",
        "        IDS = indices[k,IDX]\n",
        "        o = train_df.iloc[IDS].posting_id.values\n",
        "        preds.append(o)\n",
        "        \n",
        "del model, distances, indices, vectors, IDX, o, IDS\n",
        "_ = gc.collect()"
      ],
      "metadata": {
        "id": "b1KPGhWs8SBx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['preds_concat'] = preds\n",
        "train_df.head()"
      ],
      "metadata": {
        "id": "mCvaKQg08SJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del preds"
      ],
      "metadata": {
        "id": "rUAXnKu-8SRx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['f1_concat'] = train_df.apply(getMetric('preds_concat'), axis=1)\n",
        "print('CV score for baseline =', train_df.f1_concat.mean())"
      ],
      "metadata": {
        "id": "TvxEETkO8SbR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tmp = train_df.groupby('image_phash').posting_id.agg('unique').to_dict()\n",
        "train_df['preds_phash'] = train_df.image_phash.map(tmp)\n",
        "train_df.head()"
      ],
      "metadata": {
        "id": "cWqche138SiZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del tmp"
      ],
      "metadata": {
        "id": "CKgoPzm98SoM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_gf = cudf.DataFrame(train_df[['posting_id', 'title']])"
      ],
      "metadata": {
        "id": "viCgMncr8Sr3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = TfidfVectorizer(stop_words='english', binary=True, max_features=25_000)\n",
        "text_embeddings = model.fit_transform(dataset_gf.title)"
      ],
      "metadata": {
        "id": "Y7ymav2p8SxT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del model"
      ],
      "metadata": {
        "id": "sTd0H8MR8S2o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = []\n",
        "CHUNK = 1024\n",
        "\n",
        "print('Finding similar titles...')\n",
        "CTS = len(train_df)//CHUNK\n",
        "if len(train_df)%CHUNK!=0: CTS += 1\n",
        "for j in range( CTS ):\n",
        "    \n",
        "    a = j*CHUNK\n",
        "    b = (j+1)*CHUNK\n",
        "    b = min(b,len(train_df))\n",
        "    print('chunk',a,'to',b)\n",
        "    \n",
        "    # COSINE SIMILARITY DISTANCE\n",
        "    cts = text_embeddings.dot(text_embeddings[a:b].T).T.toarray()\n",
        "    \n",
        "    for k in range(b-a):\n",
        "        IDX = cupy.where(cts[k,]>0.7)[0]\n",
        "        o = train_df.iloc[cupy.asnumpy(IDX)].posting_id.values\n",
        "        preds.append(o)\n",
        "        \n",
        "del text_embeddings, IDX, o, cts\n",
        "_ = gc.collect()"
      ],
      "metadata": {
        "id": "Z8rC6l1o8S7H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['preds_tfidf'] = preds"
      ],
      "metadata": {
        "id": "X099sWu08l-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del preds"
      ],
      "metadata": {
        "id": "wYxB-3Di8mE4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['f1_tfidf'] = train_df.apply(getMetric('preds_tfidf'), axis=1)\n",
        "print('CV score for baseline =', train_df.f1_tfidf.mean())"
      ],
      "metadata": {
        "id": "oZI1na-98mKx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def combine_for_sub(row):\n",
        "    x = np.concatenate([row.preds_concat,row.preds_phash, row.preds_tfidf])\n",
        "    return ' '.join( np.unique(x) )\n",
        "\n",
        "def combine_for_train(row):\n",
        "    x = np.concatenate([row.preds_concat,row.preds_phash, row.preds_tfidf])\n",
        "    return list(np.unique(x))"
      ],
      "metadata": {
        "id": "duXl6P1x8mRM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['matches'] = train_df.apply(combine_for_train, axis=1)"
      ],
      "metadata": {
        "id": "XGrf8InA8mU2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.to_pickle('train_data.pkl')"
      ],
      "metadata": {
        "id": "fxMreAeC8mZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df[['posting_id', 'matches']].to_csv('submission.csv',index=False)"
      ],
      "metadata": {
        "id": "iMhmvAFp8mfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "subm = pd.read_csv('submission.csv')\n",
        "subm.head()"
      ],
      "metadata": {
        "id": "JfqcUr9j8yiB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['f1_final'] = train_df.apply(getMetric('matches'), axis=1)\n",
        "print('CV score for baseline =', train_df.f1_final.mean())"
      ],
      "metadata": {
        "id": "syNt1GKe8ynN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W2pHRdvq8yr3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4kE1VT9T8yxq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}